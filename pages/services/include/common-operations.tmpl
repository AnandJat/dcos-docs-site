This guide has so far focused on describing the components, how they work, and how to interact with them. At this point we'll start looking at how that knowledge can be applied to a running service.

## Initial service configuration

The DC/OS package format allows packages to define user-visible installation options. To ensure consistent installations, we recommend exporting the options you use into an `options.json` file, which can then be placed in source control and kept up to date with the current state of the cluster. Keeping these configurations around will make it easy to duplicate or reinstall services using identical configurations.

Use the CLI command dcos package describe {{ model.packageName }} --config to see what options are available.

```bash
$ dcos package describe elastic --config
{
  "properties": {
    <service details in JSON>
  }
}
...
```

After setting the correct values in the service configuration in a saved JSON file, you can then install the service with those options.

```bash
$ dcos package install --options=<path-to-service-json> {{ model.packageName }}
```

Be sure to add your finalized configuration to source control.


### Pod operations

Most operations for maintaining a service will involve interacting with and manipulating its [Pods](#pods).

#### Add or Remove a pod

Adding or removing pod instances within the service is treated as a configuration change, not a command.

In this case, we're increasing a pod count value, as provided by the service's configuration schema. In the case of the above `dse` service, we need to increase the configured `dsenode.count` from `3` (the default) to `4`. After the change, the Scheduler will deploy a new DSE node instance without changing the preexisting nodes.

For safety reasons, pod instances cannot be removed after they have been deployed by default. However, some services may allow some pods to be removed in cases where doing so is not a problem. To remove pod instances, you would simply decrease the count value, and then instances exceeding that count will be removed automatically in reverse order. For example, if you decreased `dsenode.count` from `4` to `2` and this was allowed by the DSE service, you would see `dsenode-3` be removed followed by `dsenode-2`, leaving only `dsenode-0` and `dsenode-1` still running. If the DSE service doesn't allow the number of instances to be decreased, the Scheduler would instead reject the decrease and show a validation error in its [deploy Plan](#status).

#### Restart a pod

Restarting a pod keeps it in the current location and leaves data in any persistent volumes as-is. Data outside of those volumes is reset via the restart. Restarting a pod may be useful if an underlying process is broken in some way and just needs a kick to get working again.

Restarting a pod can be done either via the CLI or via the underlying Scheduler API. Both forms use the same [API](http://mesosphere.github.io/dcos-commons/reference/swagger-api/). In these examples we list the known pods, and then restart the one named `dse-1`, which contains tasks named `dse-1-agent` and `dse-1-node`:

Via the CLI:

```bash
$ dcos datastax-dse --name=mydse pod list
[
  "dse-0",
  "dse-1",
  "dse-2",
  "opscenter-0",
  "studio-0"
]
$ dcos datastax-dse --name=mydse pod restart dse-1
{
  "pod": "dse-1",
  "tasks": [
    "dse-1-agent",
    "dse-1-node"
  ]
}
```

Via the HTTP API directly:

```bash
$ curl -k -H "Authorization: token=$(dcos config show core.dcos_acs_token)" <dcos-url>/service/dse/v1/pod
[
  "dse-0",
  "dse-1",
  "dse-2",
  "opscenter-0",
  "studio-0"
]
$ curl -k -X POST -H "Authorization: token=$(dcos config show core.dcos_acs_token)" <dcos-url>/service/dse/v1/pod/dse-1/restart
{
  "pod": "dse-1",
  "tasks": [
    "dse-1-agent",
    "dse-1-node"
  ]
}
```

All tasks within the pod are restarted as a unit. The response lists the names of the two tasks that were members of the pod.

#### Replace a pod

Replacing a pod discards all of its current data and moves it to a new random location in the cluster. As of this writing, you can technically end up replacing a pod and have it go back where it started. Replacing a pod may be useful if an agent machine has gone down and is never coming back, or if an agent is about to undergo downtime.

Pod replacement is not currently done automatically by the SDK, as making the correct decision requires operator knowledge of cluster status. Is a node really dead, or will it be back in a couple minutes? However, operators are free to build their own tooling to make this decision and invoke the replace call automatically.

As with restarting a pod, replacing a pod can be done either via the CLI or by directly invoking the HTTP API. The response lists all the tasks running in the pod which were replaced as a result:

```bash
$ dcos datastax-dse --name=mydse pod replace dse-1
{
  "pod": "dse-1",
  "tasks": [
    "dse-1-agent",
    "dse-1-node"
  ]
}
```

```bash
$ curl -k -X POST -H "Authorization: token=$(dcos config show core.dcos_acs_token)" http://yourcluster.com/service/dse/v1/pod/dse-1/replace
{
  "pod": "dse-1",
  "tasks": [
    "dse-1-agent",
    "dse-1-node"
  ]
}
```

#### Pause a pod

Pausing a pod relaunches it in an idle command state. This allows the operator to debug the contents of the pod, possibly making changes to fix problems. While these problems are often fixed by just replacing the pod, there may be cases where an in-place repair or other operation is needed.

For example:
- A pod which crashes immediately upon starting may need additional work to be performed.
- Some services may _require_ that certain repair operations be performed manually when the task itself isn't running.
Being able to put the pod in an offline but accessible state makes it easier to resolve these situations.

After the pod has been paused, it may be started again, at which point it will be restarted and will resume running task(s) where it left off.

Here is an example session where an `index-1` pod is crash looping due to some corrupted data in a persistent volume. The operator pauses the `index-1` pod, then uses `task exec` to repair the index. Following this, the operator starts the pod and it resumes normal operation:

```bash
$ dcos myservice debug pod pause index-1
{
  "pod": "index-1",
  "tasks": [
    "index-1-agent",
    "index-1-node"
  ]
}

$ dcos myservice pod status
myservice
├─ index
│  ├─ index-0
│  │  ├─ index-0-agent (COMPLETE)
│  │  └─ index-0-node (COMPLETE)
│  └─ index-1
│     ├─ index-1-agent (PAUSING)
│     └─ index-1-node (PAUSING)
└─ data
   ├─ data-0
   │  └─ data-0-node (COMPLETE)
   └─ data-1
      └─ data-1-node (COMPLETE)

... repeat "pod status" until index-1 tasks are PAUSED ...

$ dcos task exec --interactive --tty index-1-node /bin/bash
index-1-node$ ./repair-index && exit

$ dcos myservice debug pod resume index-1
{
  "pod": "index-1",
  "tasks": [
    "index-1-agent",
    "index-1-node"
  ]
}

$ dcos myservice pod status
myservice
├─ index
│  ├─ index-0
│  │  ├─ index-0-agent (RUNNING)
│  │  └─ index-0-node (RUNNING)
│  └─ index-1
│     ├─ index-1-agent (STARTING)
│     └─ index-1-node (STARTING)
└─ data
   ├─ data-0
   │  └─ data-0-node (RUNNING)
   └─ data-1
      └─ data-1-node (RUNNING)

... repeat "pod status" until index-1 tasks are RUNNING ...
```

In the above example, all tasks in the pod were being paused and started, but it's worth noting that the commands also support pausing and starting individual tasks within a pod. For example, `dcos myservice debug pod pause index-1 -t agent` will pause only the `agent` task within the `index-1` pod.

### Plan Operations

This lists available commands for viewing and manipulating the Plans used by the Scheduler to perform work against the underlying service.

#### List
Show all plans for this service.

```bash
dcos kakfa plan list
```

#### Status
Display the status of the plan with the provided plan name.

```bash
dcos kafka plan status deploy
```

**Note:** The `--json` flag, though not default, is helpful in extracting phase UUIDs. Using the UUID instead of name for a
phase is a more ensures that the request, ie to pause or force-complete, is exactly the phase intended.

#### Start
Start the plan with the provided name and any optional plan arguments.

```bash
dcos kafka plan start deploy
```

#### Stop
Stop the running plan with the provided name.

```bash
dcos kafka plan stop deploy
```

Plan Pause differs from Plan Stop in the following ways:
* Pause can be issued for a specific phase or for all phases within a plan. Stop can only be issued for a plan.
* Pause updates the underlying Phase/Step state. Stop not only updates the underlying state, but also restarts the plan.

#### Pause
Pause the plan, or a specific phase in that plan with the provided phase name (or UUID).

```bash
dcos kafka plan pause deploy 97e70976-505f-4689-abd2-6286c4499091
```

**NOTE:** The UUID above is an example. Use the Plan Status command with the `--json` flag to extract a valid UUID.

Plan Pause differs from Plan Stop in the following ways:
* Pause can be issued for a specific phase or for all phases within a plan. Stop can only be issued for a plan.
* Pause updates the underlying Phase/Step state. Stop not only updated the underlying state, but also restarts the plan.

#### Resume
Resume the plan, or a specific phase in that plan, with the provided phase name (or UUID).

```bash
dcos kafka plan resume deploy 97e70976-505f-4689-abd2-6286c4499091
```

#### Force-Restart
Restart the plan with the provided name, or a specific phase in the plan, with the provided nam, or a specific step in a
phase of the plan with the provided step name.

```bash
dcos kafka plan force-restart deploy
```

#### Force-Complete
Force complete a specific step in the provided phase. Example uses include the following: Abort a sidecar operation due
to observed failure or due to known required manual preparation that was not performed.

```bash
dcos kafka plan force-complete deploy
```
